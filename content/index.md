---
title: "Home"
draft: false
---

<div id="about-me-photo">
<img src="/static/96168057.jpg" alt="Ning Wang">
</div>

# About Me

I'm Ning Wang, a 19-year-old Master's student at ETH Zurich.
I am interested in machine learning research, in particular large language models, and have been involved in multiple research projects. I currently work as a research assistant at ETH Zurich and at the MPI. 

## Research Interests

- LLM safety
- LLM reasoning
- Time series prediction
- ML for biology

## Recent Work

I worked on / am working on the following projects:

- Sparse time series prediction using a custom Transformer, MoE, and benchmarking the performance of these models and models such as Chronos, Sundial, TimeSFM,...

- Coding perturbation for LLM training data contamination detection, using ICL, context and constraint perturbations
  
- Cross-domain transferability of fine-tuning smaller models using CoT of larger models (for domains like math, physics, coding)
  
I have assisted in the following projects:

- Benchmarking the performance of LLMs in TCS, in particular Lean proofs (Busy Beavers and Mixed Boolean Arithmetic), ICML workshop paper
  
- Benchmarking the performance of LLMs in questions retrieved from ArXiv papers, across time to detect the effect of knowledge cutoff (result being the models being actually better after the cutoff), in submission
  
I am now mainly interested in LLM safety, in addition to completing the current ongoing projects. 

## Contact

- Email: wangni@ethz.ch
- GitHub: github.com/cs-2006
- LinkedIn: linkedin.com/in/the-time

Feel free to reach out if you'd like to discuss machine learning research, in particular LLMs, or potential collaborations!

## Website TODO
Trivia and links don't work and GPT-5 doesn't know to debug? Check back later
