---
title: "Now"
draft: false
---
# Now

*Last updated: 08-2025*

## What I'm Working On

Currently in my Master's program at ETH Zurich, focusing on machine learning. 

### Current Projects

I worked on / am working on the following projects:

- Sparse time series prediction using a custom Transformer, MoE, and benchmarking the performance of these models and models such as Chronos, Sundial, TimeSFM,...

- Coding perturbation for LLM training data contamination detection, using ICL, context and constraint perturbations
  
- Cross-domain transferability of fine-tuning smaller models using CoT of larger models (for domains like math, physics, coding)
  
I have assisted in the following projects:

- Benchmarking the performance of LLMs in TCS, in particular Lean proofs (Busy Beavers and Mixed Boolean Arithmetic), ICML workshop paper
  
- Benchmarking the performance of LLMs in questions retrieved from ArXiv papers, across time to detect the effect of knowledge cutoff (result being the models being actually better after the cutoff), in submission
  
I am now mainly interested in LLM safety, in addition to completing the current ongoing projects. 

### Some Relevant (ML or related) Courses I've Taken

- Advanced ML 
- Probabilistic AI
- Computational Intelligence Lab
- AI Center Projects in ML Research
- Deep Learning
- Computational Semantics for NLP
- Diffusion Models, Sampling and Stochastic Localization
- Machine Perception
- Complex Network Models
- Pattern matching beyond i.i.d. data (seminar)
- Advanced Topics in Machine Learning (seminar)

## What I'm Learning

Reading research papers and learning about automation tools

## What I'm Thinking About

How to make LLMs safe and performant?

## Outside Academia

- Music
- Table tennis
- Formerly gaming (not anymore)

---

[What is a "now" page?](https://nownownow.com/about)
